{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnlYhk4g0IkB"
      },
      "source": [
        "The code is based on kaggle project:\n",
        "https://www.kaggle.com/code/rajmehra03/flower-recognition-cnn-keras\n",
        "Flower Recognition CNN Keras, RAJ MEHROTRA, 2019"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDiP6PaqP7l_"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/j-anne/ML_flower_recognition.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PeVQ28sPdci"
      },
      "source": [
        "Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPKX7bqvtJYa"
      },
      "outputs": [],
      "source": [
        "# Getting file path\n",
        "import os\n",
        "\n",
        "# data visualisation and manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import seaborn as sns\n",
        " \n",
        "#configure\n",
        "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
        "%matplotlib inline  \n",
        "style.use('fivethirtyeight')\n",
        "sns.set(style='whitegrid',color_codes=True)\n",
        "\n",
        "#model selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#preprocess.\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#dl libraraies\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# specifically for cnn\n",
        "from keras.layers import Dropout, Flatten,Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        " \n",
        "import tensorflow as tf\n",
        "import random as rn\n",
        "\n",
        "# specifically for manipulating zipped images and getting numpy arrays of pixel values of images.\n",
        "import cv2                  \n",
        "from tqdm import tqdm                \n",
        "from random import shuffle  \n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADSff68EbP73"
      },
      "source": [
        "**Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nn7jXYitDre"
      },
      "outputs": [],
      "source": [
        "train_images = []\n",
        "train_labels = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgTkHgbtsQ3T"
      },
      "outputs": [],
      "source": [
        "def load_images(DIR):\n",
        "    for flower in tqdm(os.listdir(DIR)):\n",
        "      label = flower\n",
        "      path = DIR +'/'+ flower\n",
        "\n",
        "      for image in os.listdir(path):\n",
        "        img = cv2.imread(path+'/'+image)\n",
        "        img = np.array(img).astype('uint8')\n",
        "        img = cv2.resize(img, (150, 150))\n",
        "\n",
        "        train_images.append(img)\n",
        "        train_labels.append(label)\n",
        "\n",
        "load_images(\"/content/ML_flower_recognition/flowers\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLczSF2qse_6"
      },
      "outputs": [],
      "source": [
        "fig,ax=plt.subplots(2,3)\n",
        "fig.set_size_inches(10,10)\n",
        "for i in range(2): \n",
        "  for j in range (3):\n",
        "      l=rn.randint(0,len(train_labels))\n",
        "      ax[i,j].imshow(train_images[l])\n",
        "      ax[i,j].set_title(train_labels[l])\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoTbARiDbJ_B"
      },
      "source": [
        "**Builing the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVXxpXLeZpb3"
      },
      "outputs": [],
      "source": [
        "# modelling starts using a CNN.\n",
        "# Uses RELU and Softmax for activation function\n",
        "# Building convolutional model\n",
        "model = Sequential()\n",
        "\n",
        "# Input Layer\n",
        "model.add(Conv2D(32, kernel_size=(5,5), padding = 'Same',activation ='relu', input_shape = (150,150,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Convolution Layer\n",
        "model.add(Conv2D(64, kernel_size=(3,3), padding = 'Same',activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(96, kernel_size=(3,3), padding = 'Same',activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(128, kernel_size=(3,3), padding = 'Same',activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Fully connected layer\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.7))\n",
        "\n",
        "model.add(Dense(1000))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(len(train_images), activation = \"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1ncCilw2Lj1"
      },
      "outputs": [],
      "source": [
        "# One Hot Encoding\n",
        "le=LabelEncoder()\n",
        "encoded_label=le.fit_transform(train_labels)\n",
        "encoded_label=to_categorical(encoded_label,len(encoded_label))\n",
        "\n",
        "# using cv2 for normalization\n",
        "normalize_data = []\n",
        "\n",
        "for img in train_images:\n",
        "  norm = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "  normalize_data.append(norm)\n",
        "\n",
        "normalize_data = np.array(normalize_data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BPgKIrlO51f"
      },
      "outputs": [],
      "source": [
        "print(f\"Normalize data shape: {normalize_data.shape}\")\n",
        "print(f\"Encoded label shape: {encoded_label.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGIhFLmKj_nM"
      },
      "outputs": [],
      "source": [
        "plt.imshow(normalize_data[28])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGlNnEISa-Rc"
      },
      "source": [
        "**Train and Test Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkn_i4ihyoFO"
      },
      "outputs": [],
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(normalize_data,encoded_label,test_size=0.25,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20_romcWYRGp"
      },
      "outputs": [],
      "source": [
        "# To resolve randomness of the model result\n",
        "np.random.seed(42)\n",
        "rn.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGs5gh2HZttK"
      },
      "outputs": [],
      "source": [
        "batch_size=60\n",
        "epochs=100\n",
        "\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "red_lr= ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VcU6ZAlbbZf"
      },
      "source": [
        "**Data Optimization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfe20N9QZ2wm"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.2, # Randomly zoom image \n",
        "        horizontal_flip=True)  # randomly flip images horizontally\n",
        "\n",
        "datagen.fit(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImOF-c-cblOB"
      },
      "source": [
        "**Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hY9hb6-Z5K5"
      },
      "outputs": [],
      "source": [
        "#Creates our batch of one image\n",
        "fig,ax=plt.subplots(2,3)\n",
        "fig.set_size_inches(10,10)\n",
        "\n",
        "for i in range(2): \n",
        "  for j in range (3):\n",
        "      l=rn.randint(0,len(train_labels))\n",
        "      ax[i,j].imshow(normalize_data[l])\n",
        "      ax[i,j].set_title('Flower: '+train_labels[l])\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9h8bvOob1Cv"
      },
      "source": [
        "**Fitting the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2KxCrWfaTWq"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.01),loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JrsH9H9ajA6"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "covYIL-salgL"
      },
      "outputs": [],
      "source": [
        "History = model.fit(datagen.flow(x_train,y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = (x_test,y_test),\n",
        "                              verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYYbnvAqat3K"
      },
      "outputs": [],
      "source": [
        "plt.plot(History.history['loss'])\n",
        "plt.plot(History.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()\n",
        "\n",
        "print('The loss value is: ', History.history['loss'][-1])\n",
        "print('The val loss value is: ', History.history['val_loss'][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-ZXdalpqey6"
      },
      "outputs": [],
      "source": [
        "plt.plot(History.history['accuracy'])\n",
        "plt.plot(History.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()\n",
        "\n",
        "print('The accuracy of the model is: ', int(History.history['accuracy'][-1] * 100), '%')\n",
        "print('The val accuracy of the model is: ', int(History.history['val_accuracy'][-1] * 100), '%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_JP4zPfqiam"
      },
      "outputs": [],
      "source": [
        "# getting predictions on val set.\n",
        "pred=model.predict(x_test)\n",
        "pred_digits=np.argmax(pred,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGuY7CV2qp1w"
      },
      "outputs": [],
      "source": [
        "# now storing some properly as well as misclassified indexes'.\n",
        "i=0\n",
        "prop_class=[]\n",
        "mis_class=[]\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    if(np.argmax(y_test[i])==pred_digits[i]):\n",
        "        prop_class.append(i)\n",
        "#     if(len(prop_class)==8):\n",
        "#         break\n",
        "\n",
        "i=0\n",
        "for i in range(len(y_test)):\n",
        "    if(not np.argmax(y_test[i])==pred_digits[i]):\n",
        "        mis_class.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KngiEJiZq90t"
      },
      "outputs": [],
      "source": [
        "print(f\"Count of proper predicted images: {len(prop_class)}\")\n",
        "print(f\"Count of mis-predicted images: {len(mis_class)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOoXmKTOqsvM"
      },
      "outputs": [],
      "source": [
        "count=0\n",
        "fig,ax=plt.subplots(4,2)\n",
        "fig.set_size_inches(15,15)\n",
        "for i in range (4):\n",
        "    for j in range (2):\n",
        "        ax[i,j].imshow(x_test[prop_class[count]])\n",
        "        ax[i,j].set_title(\"Predicted Flower : \"+str(le.inverse_transform([pred_digits[prop_class[count]]]))+\"\\n\"+\"Actual Flower : \"+str(le.inverse_transform([np.argmax(y_test[prop_class[count]])])))\n",
        "        plt.tight_layout()\n",
        "        count+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZGoUWQbqv5A"
      },
      "outputs": [],
      "source": [
        "count=0\n",
        "fig,ax=plt.subplots(4,2)\n",
        "fig.set_size_inches(15,15)\n",
        "for i in range(4):\n",
        "    for j in range (2):\n",
        "        ax[i,j].imshow(x_test[mis_class[count]])\n",
        "        ax[i,j].set_title(\"Predicted Flower : \"+str(le.inverse_transform([pred_digits[mis_class[count]]]))+\"\\n\"+\"Actual Flower : \"+str(le.inverse_transform([np.argmax(y_test[mis_class[count]])])))\n",
        "        plt.tight_layout()\n",
        "        count+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHtiCy15qy0F"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}